%% The following is a directive for TeXShop to indicate the main file
%%!TEX root = diss.tex

\chapter{Background}
\label{ch:rw}

In this chapter, we provide the relevant background for this dissertation.
We begin with an overview of haptic technology and perception.
Next, we discuss the application space for haptics and why haptic experiences are increasingly important to design.
We then discuss non-haptic creativity support tools and design theory which provided inspiration and guiding principles.
After, we discuss the previous work in \haxd and related support tools, identifying why this is an area for improved understanding.
Finally, we present the qualitative and quantitative methodologies used in this dissertation.
Throughout the chapter, we contextualize this work and \haxd in both the haptics and HCI communities.


%%%%%%%%%%%%
%
% SECTION: What is haptics?
%
%%%%%%%%%%%%
\section{An Overview of Haptic\osE{s}}
The term ``haptic" was coined \revRG{in 1892} by German researcher Max Dessoir to refer to the study of touch, similar to ``optic" for sight and ``acoustic" for sound \cite{Grunwald2008}.
Today, it refers to both the study of the psychology and perception of the senses of touch, and the technology that employs touch as a method of feedback.
Haptic technology is typically separated into two classes based on the main sense modality: \emph{tactile} (or \emph{cutaneous}) sensations, and \emph{proprioception}, or the sense of body location and force;  the latter includes \emph{kinaesthetic} senses of force and motion.
These two types of feedback are useful for different purposes, \eg, people use their fingerpad's tactile senses to derive texture, but kinaesthetic feedback to infer weight \cite{Lederman1987};
different senses can be combined for more convincing results \cite{Okamura1998}.
For an overview of the haptic senses, we direct the reader to \citet{Lederman2009survey}; for a practical introduction to haptic technology, we suggest \citet{Hayward2007}.
We focus our coverage on the sensations directly studied by this dissertation \revRG{(vibrotactile feedback, programmable friction, simple force-feedback, simple haptic robots)}, while also portraying the diversity of haptic experiences and technology.

\subsection{Tactile Perception and Technology}
Tactile sensations rely on multiple sensory organs in the skin, each of which detect different properties, \eg, Merkel disks detect pressure or fine details, Meissner corpuscles detect fast, light sensations (flutter), Ruffini endings detect stretch, and Pacinian corpuscles detect vibration \cite{ChoiKuchenbecker2013}.
\osE{Haptic technology has evolved along two parallel paths: stimulating sensory mechanisms and mimicking realistic environments.}
\osE{Tactile technologies are at least as diverse as the senses they stimulate and the environments they simulate.}

\osE{Vibrotactile (VT) sensations, where vibrations stimulate the skin, target} the Pacinian corpuscle.
VT actuators can take may forms\osE{; the more affordable techniques tend to directly stimulate skin.}
Eccentric mass motors (sometimes ``rumble motors" or ``pager motors") are found in many mobile devices and game controllers, and are affordable but inexpressive.
%An unbalanced mass is mounted on the motor, which provides dramatic shaking of the device.
More expressive mechanisms such as voice coils %  implemented in a variety of ways and 
offer independent control of two degrees of freedom, frequency and amplitude.
Piezo actuation is a very responsive technique that is typically more expensive than other vibrotactile technology.
% One of the more common and expressive is the C2 tactor, intended to directly stimulate the skin through contact or a thin membrane; the tactile animation project [] uses an array of C2 tactors.
While voice coils typically directly stimulate the skin, linear resonant actuators (LRAs) shake a mass back and forth to vibrate a handset in an expressive way; a common research example is the Haptuator \cite{Yao2010}.
Instead of directly stimulating the skin, this actuator typically shakes another device held by the user, such as a mobile device \cite{Yoo2014} or pen \cite{Culbertson2014}\osE{; this approach is amenable to both designed artifical stimulation and physical realism}.
As of 2016, LRAs are increasingly deployed in consumer products (\eg, Apple's Taptic Engine).

\osE{VT sensations are accessible, well-studied, and increasingly widespread, and can be passively felt, easing implementation.}
\osE{Our in-depth design tool studies thus focus on VT experiences.}
%%%%In contrast to displacing the entire user body, recent multichannel haptic devices create percepts of dynamic and localized haptic sensations directly on the user's skin \cite{Israr2011} and in the mid-air \cite{Wilson2014}.
Actuators like VT devices can be used alone or put together in spatial multiactuator displays like seats \cite{Israr2012,Israr2010}, belts \cite{Pielot2009,Paneels2013}, wristbands \cite{Arab2015,Paneels2013,Gupta2016}, vests \cite{Prasad2014,Jones2004}, and gloves \cite{Park2016,Kim2009}.
These can be arranged into grids, either dense tactile pixels (``taxels") \cite{Kim2009} or sparse arrays \cite{Israr2012,Israr2010}, to provide 2D output on a plane.
Multiactuator arrays increasingly exploit tactile illusions to create effects of motion or phantom sensations in-between actuators.

Another emerging tactile feedback mechanism is programmable friction\osE{, creating shear forces on the skin to target sensations of skin stretch.}
Surface friction, for example on a mobile touch screen, can be manipulated by both mechanical motion or electrical adhesion.
The TPad \cite{Winfield2007} vibrates a plate at ultrasonic frequencies to create a cushion of air between the surface and the user's finger.
This effect is programmable, and can be used to with a number of interactive scenarios \cite{Levesque2011}.
Other techniques like electrovibration, deployed in TeslaTouch \cite{Bau2010}, and electrostatic forces \cite{Meyer2013}, can create a similar effect.
Strong electroadhesion \cite{Shultz2015} has the potential to create very large shear forces, but comes with a high power cost.
In RoughSketch (\autoref{ch:applications}), we design for a mobile version of the TPad deployed on Android devices, the TPad phone (\url{www.thetpadphone.com}).

There are many other types of tactile stimulation used in haptic experiences.
2-dimensional pin-based grids like Optacon \cite{Bliss1970} and HyperBraille (\url{www.hyperbraille.de}) can display Braille and 2D images to the blind and visually impaired, and can operate as a generic computer display \cite{Prescher2010}. 
%"Survey on communication through touch" by pasquero, "Optical to tqactile image conversion for the blind by Bliss et all 1970.
Similar multi-point displays have been deployed on mobile devices.
Edge Haptics uses dozens of linearly-actuated pins on the edge of a mobile device for tactile stimulation, similar to braille pin displays \cite{Jang2016}, while laterally moving pins can use skin-stretch as a display mechanism \cite{Luk2006}.
Electrocutaneous stimulation, where electrodes directly stimulate the skin, has been deployed for spatial tongue displays \cite{Bach-y-Rita1998}.
Temperature displays exploit warm and cold receptors in \revRG{the} skin for display, using Peltier junctions \cite{Jones2002}.
Tactile sensations can be created at a distance using ultrasonic transducers \cite{Obrist2013,Carter2013} and vortex cannons that shoot puffs of air \cite{Sodhi2013}.



\subsection{Proprioceptive \osE{Perception and Technology}}
Proprioception, the sense of force and position, is synthesized from multiple sensors as well: the muscle spindle (embedded in muscles), golgi-tendon organ (GTO) in tendons, and tactile and visual cues \cite{Kandel2000}.
We distinguish proprioception from the related term kinaesthetic by being the general, synthesized sense, where kinaesthetic sensation is strictly the sense of motion.
Force displays are common in precise, specialized applications like robot-assisted surgery \cite{Okamura2009} or realistic sensorimotor training environments \cite{VanDerMeijden2009}.
\osE{The focus is usually on simulation, creating forces on the user from a virtual environment.}

Force-feedback devices \osE{differ in their} degrees of freedom of feedback (DoF), the number of \osE{variables needed to express their kinematic state}.
These devices render a \emph{virtual environment}, with simulated forces depending on the input from the user.
Common consumer-facing 3-DoF devices include the Geomagic Touch (previously the Sensable PHANTOM) and Falcon devices, offering force in three directions.
2-DoF designs like the pantograph \cite{Ramstein1994,Campion2005} can provide displays on screens, walls, and tables.
Research with these displays often requires realistic simulation and rendering: \eg, making free space feel free, providing stiff virtual objects and walls, and avoiding saturation  \cite{massie1994phantom}.
Open-hardware, self-assembled versions of these devices, such as WoodenHaptics \cite{Forsslund2015} for 3-DoF devices and Haplet \cite{Gallacher2016} for 2-DoF displays, have the potential to make haptics more accessible.
Much previous work has been done on handling technical concerns, \eg, displaying complex polygonal objects with a ``God object" \cite{Zilles1995}, coordinating remotely situated devices or shared environments \cite{Buttolo1997}, and improving collision realism with transient forces \cite{Kuchenbecker2006}.
More complex environments are primarily programmed in using APIs like CHAI3D, OpenHaptics, or Unity.

Another approach is to use simple force feedback, \osE{for example,} for haptics education \cite{Jones2014}.
1-DoF devices include linear actuators pushing on the user and haptic knobs, \eg, the UBC Twiddler \cite{Shaver2003,Enriquez2003,MacLean2009a}, and paddles, \eg, the HapKit \cite{Martinez2016}.
The UBC SPIN lab has also adopted 1-DoF force feedback in its affective robot, the Haptic Creature \cite{Yohanan2011affectdisplay,Yohanan2011affectivetouch}, the CuddleBot \cite{Allen2015cuddlebot}, and CuddleBits \cite{cang2015cuddlebits}.
We explore force-feedback design with the HapKit and CuddleBits in \autoref{ch:applications}.


\subsection{Haptic Illusions}
Like the stroboscopic effect transforming a series of images into the perception of motion for visual displays, illusions play a valuable role in haptic sensations \cite{Hayward2016}\osE{:}
\osE{they let a designer create convincing sensations without accurately simulating physical environments.}
Some are influenced by other senses.
In the classic size-weight illusion \cite{charpentier1891analyse}, when two weights have the same mass but different sizes, the smaller is perceived to be heavier, whether size is seen or felt \cite{Hayward2016}.
\osE{Similar effects occur with synthesized haptic effects: perceived stiffness of a spring changes with both visual distortion of the spring's position \cite{Srinivasan1996impact} and the sound that is played \cite{DiFranco1997effect}.}
A striking, recent example is the use of visual dominance to use a single physical block to provide haptic feedback for multiple virtual blocks by distorting the visual position of the user's arm \cite{Azmandian2016}.
We employ similar techniques in our FeelCraft and Feel Messenger projects, using visual feedback to prime users to haptic sensations (\autoref{ch:applications}).

Other illusions are purely tactile and useful for multiactuator displays\osE{; in these cases, they expand the haptic palette.}
Phantom tactile sensations \cite{Alles1970}, create illusory vibrations in between two or more VT actuators, opening up the space in-between actuators for display.
Continuous motion can be simulated, \eg, \citet{Seo2010} created a perceived motion flow between two VT actuators mounted on the ends of a handheld device by controlling their intensity.
Similarly, \citet{Lee2012a} created across-the-body and out-of-the-body illusions on a mobile device using up to four % inexpensive 
LRAs; \citet{Gupta2016} used interpolation on a VT wristband for new interaction techniques.
The Tactile Brush algorithm \cite{Israr2011a} combined phantom tactile sensations and apparent tactile motion to render high-resolution and moving haptic patterns on the back using a coarse grid of VT actuators. 
Other spatio-temporal VT illusions such as the ``cutaneous rabbit"  \cite{Tan2009}, where carefully timed discrete tactile stimuli create perceived motion, and Tau and Kappa effects \cite{Hayward2008,Hayward2016}, where perceived distance between stimuli depending on their timing, can also be used with VT arrays.
Similar illusions are possible using other tactile modalities, including temperature displays \cite{Singhal2016} and electrocutaneous stimulation \cite{Tanie1980}.
We extend phantom VT sensations to 2D interpolation (\eg, between 3 actuators) to enable Tactile Animation (\autoref{ch:tactileanimation}).

%\osE{Force feedback in a plane can feel like bumps and curves \cite{Morgenbesser1996force}.}


Of course, haptic perception can depend on the user's physical and attentional connection with the device, especially important in wearable contexts.
Vibrotactile detection depends on many variables, including location on the user's body, how much the user is moving, and whether they are expecting the vibration \cite{Karuei2011}, and social context \cite{Cauchard2016}.
These effects can be mitigated through sensing, \eg, detecting movement with accelerometers \cite{Blum2015}.
The implications of context on \haxd are discussed by professional designers in \autoref{ch:hapticianinterviews}.




%\inlineHeading{Multimodal interaction}
%Similar to vision and audio, haptic perception is susceptible to illusions \cite{Hayward2016,Hayward2008}.
%
%discuss passiveness, like cobots, etc.

%%%%%%%%%%%%
%
% SECTION: Why should we care about haptics?
%
%%%%%%%%%%%%
\section{The Value of Haptic Experiences}
Haptic feedback can provide several benefits to interactive experiences.
Here, we outline the main benefits haptics provides, and then several application areas that commonly leverage those benefits.


\subsection{Why Touch?}
Haptic technology enables information transfer between humans and computers;
this transfer is rich, proximal, and fast.
Information flows both ways, through input and output, sometimes simultaneously.
We focus on designed haptic display.

One advantage of touch is simply that it is not vision or audio, the primary feedback methods for interactive systems.
Haptic technology can reinforce other modalities, enriching feedback for a more complete experience, or
provide complementary feedback, with many possible reasons:
information saturation, \eg, when visual or audio displays have maximized their output;
task context, \eg, when the user is driving and must keep their eyes on the road;
impairment or impairing situations, \eg, when a user has limited sight or hearing;
ambient displays, \eg, keeping a user aware of a piece of information without interrupting them;
or nature of the information, \eg, communicating emotion.
%It can increase general usability and provide an alternative path for information when other modalities are not available (\eg, the users are visually-impaired) or not appropriate (\eg, looking at a screen would be socially inappropriate).
\osE{For example, touch can be used \revRG{as} a substitute for other senses} \cite{Bach-y-Rita1969}, \osE{and the result can be dramatic, \eg, a blind person using a tongue-based display to seeing a rolling ball well enough to bat it as it falls \cite{Bach-y-Rita2003}.}
\osE{Many} other devices have been developed and studied for the visually impaired (\eg, \cite{Prescher2010,Bliss1970}).

Of course, touch is a unique, rich sense in its own right.
\revRG{Touch can be both invisible, like sound, and spatial, like vision.}
%Like sound, touch can be invisible; like vision, it can be spatial.
Touch is the first sense to develop, playing an important role in formative experiences \cite{Jansson-Boyd2011};
sensorimotor actions can help to scaffold understanding through embodied learning \cite{Papert1980}.
\revRG{Feeling an object is especially helpful at discerning material properties \cite{Lederman1987}.}
Touch can also be used for artistic expression\revRG{:} \citet{Gunther2002} studied a full-body vibrotactile suit to create music-like ``cutaneous grooves", helping to identify the artistic space of VT sensations, including concerts with tactile compositions.

While haptic feedback can improve usability and task performance \cite{Pielot2009,Chan2008}, touch is especially connected to visceral, emotional connections.
Marketing research has studied multiple ways that touch can connect with customers:
the way a smartphone feels can influence a purchase over an alternative that might work better, and customers prefer to shop at stores that let them touch products \cite{Spence2011,Jansson-Boyd2011}.





%emotion theory background
%Emotion can play different roles in technology, such as affective technology, hedonic qualities, or interactional dynamics \cite{Hook2008bodyemotion} \osC{need to dig deep to understand this}





%; see \citep{Hamilton-Fletcher2016} for a recent survey and discussion of user preferences.


%In many of these contexts, careful design is required.
% \citet{Arab2015}'s wrist based display worked best when using a metaphor-based approach \cite{Brunet2013a}, co-designing metaphors with their users.
% \citet{Cauchard2016} found rhythm-based pulses were more effective for portraying numbers in their in-situ study.




\subsection{Applications}
While realistic virtual environments for force-feedback haptic feedback are helpful in medical or training applications  \cite{Okamura2009,VanDerMeijden2009}, we focus on applications \osE{that benefit from} an explicit \osE{experience} design step\osE{: gathering requirements from end-uers, iteratively exploring many ideas, and evaluating the experience of use.}
%note: EXPERIENCE design step


\subsubsection{Immersion}
\osE{Touch can subtly draw a user into an experience.}
A popular application is augmented, immersive media experiences.
Actuated tactile feedback has been used as early as 1959 in the movie \emph{The Tingler}  \cite{IJsselsteijn2003}.
4D theatres and theme park rides use bursts of air or water sprays to engage the audience.
Companies like D-Box (\url{www.d-box.com}) augment films with haptic tracks that \revRG{feature} both low-frequency movements and high-frequency vibrations, and can be found in theatres across the world.
Buttkicker (\url{www.thebuttkicker.com}) also augments 4D theatres, and provides products for home theatre setups.
\osE{In these experiences, we need to support designers' artistic control over the sense of touch.}

Haptic experiences are also increasingly of interest in virtual reality (VR) environments \osE{for, \eg, entertainment, training, and education.}
Skin stretch techniques, \osE{measured by \citet{Levesque2003lateralskinstrain}, have been explored in mobile displays \cite{Luk2006,Guinan2014}} and are now commercialized by Tactical Haptics (\url{tacticalhaptics.com}) \osE{to augment} virtual-reality setups by simulating forces and torques using handheld controllers, lending stronger immersion for virtual environments and VR games.
Haptic Turk \cite{Cheng2014} and TurkDeck \cite{Cheng2015} are innovative explorations of high-fidelity haptic experiences in virtual environments using people as actuators.
Impacto uses electrical muscle stimulation and a solenoid actuator to create wearable kinaesthetic and tactile feedback \cite{Lopes2015}.
Haptic retargeting distorts visual feedback to re-use a single physical block in a virtual block-building game \cite{Azmandian2016}.

Previous work has also attempted to add greater immersion to broadcast media by including haptic sensations.
\citet{Modhrain2001} present an early vision of Touch TV, using active touch with two-DOF actuators embedded in remote controllers; \citet{Gaw2006} follow up with editable position playback on a force-feedback device, played alongside movies or cartoons.
More recently, the proliferation of online streaming video has developed opportunities to add haptic sensations using novel data formats \revRG{that can handle diverse and interactive feedback, from forces to temperature}.
Researchers have looked at how to integrate a haptic track into Tactile Movies \cite{Kim2009}, YouTube  \cite{Gao2013}, or haptic-audiovisual (HAV) content \cite{Danieau2013}, complete with compositional guidelines drawing inspiration from film and animation \cite{Guillotel2016}.

%\subsubsection{Low-attention feedback}
%Subtle haptics, and display information without interruption


\subsubsection{Affect}
Researchers are \osE{developing} design guidelines to express emotions through haptic experiences.
Low-level parameters like amplitude, frequency, and duration have been linked to emotions\osE{, \eg, with VT icons} \cite{YongjaeYoo2015} \osE{and mid-air ultrasound stimulation}
\cite{Obrist2015}.
Because touch can be bidirectional, affective sensing can accompany haptic display.
The Haptic Creature project established a touch dictionary of gestures that emotionally communicate with robots \cite{Yohanan2011affectivetouch}.
Touch-based surfaces can detect these gestures \cite{Flagg2013} through technologies like conductive fur and fabric \cite{Flagg2012}.

To study emotion and technology, researchers commonly draw from two affective models:
Ekman's basic emotions and Russell's affect grid.
Ekman's basic emotions \cite{Ekman1992,Ekman1971} are a discrete set of emotions identified from a cross-cultural study of facial expressions; we use this model's emotions as the design task in \autoref{ch:hapticinstrument}.
Russell's affect grid \cite{Russell1989circumplexmodel,Russell1989affectgrid} separates emotions into dimensions of arousal (low to high energy) and valence (positive and negative emotions); this work informs \revRG{our perspective} %much of our work
on expressivity\revRG{, especially with} the CuddleBit work in \autoref{sec:applications:cuddlebit}.

\osE{The emotional nature of touch} has implications for design;
for example, couples are more comfortable \osE{than strangers when using} a ``hand stroke" metaphor for two remotely coupled haptic devices \cite{Smith2007}.
Emotional display through touch has therapeutic applications.
\citet{Bonanni2006} created TapTap, a wearable that can record and playback VT equivalents of affectionate touch to support users in therapy.
Tactile displays \revRG{target mental} health \cite{Vaucelle2009} \revRG{and emotional} understanding for autism \cite{Changeon2012}.
The Haptic Creature project explores affective touch in human-robot interaction (HRI) \cite{Yohanan2005,Yohanan2009,Yohanan2011affectivetouch,Yohanan2011affectdisplay};
this furry, zoomorphic robot can measurably relax users when they feel it breath \cite{Sefidgar2016}.
%\osE{Emotional haptic interfaces benefit from an explicit design process by a) understanding guidelines on how to use emotions in haptic experiences, and b) require emotional sensations to be designed in some modalities -- what does an angry vibration feel like?}
Emotional haptic interfaces benefit from an explicit design process\revRG{, as
designers can draw from guidelines on how to consider emotion in haptic experiences.}





\subsubsection{\osE{Expressive Interpersonal} Communication}
%interpersonal touch, and haptic interpretations of it
Touch is extremely important for interpersonal communication, from greeting a new acquaintance with firm handshake, to showing affection to a loved one \revRG{with a long hug}; see \citet{Gallace2010} for an overview.
Of course, technology can mediate touch between people, \eg, in remote collaboration or shared virtual environments \cite{Haans2006}.
\citet{Brave1997} introduced ``inTouch", mechanically linked rollers that enabled playful touch interactions at a distance.
ComTouch \cite{Chang2002a} used pressure input to send vibrations \revRG{between} mobile phones, finding it was used for attention, turn-taking, and emphasis.
\citet{Hoggan2012} elaborated \revRG{on} these findings\revRG{:} a one month-study found users sent ``Pressages" (pressure messages) both for greetings and to emphasize speech or emotional messages.
\citet{Chan2008} used VT icons to coordinate turn-taking in an online system, featuring an extensive design process to create and perceptually verify icons that present system state and requests with varying urgency.
%\citet{Brown2006multidimensionaltactons} used tactons displayed on a user's forearm \osC{this is actually kinda boring this study}
%\osE{A design step can help build languages for communication, helping end-users find the right haptic words to express themselves.}
A design step can help build languages for communication, \revRG{providing the right haptic words for users to express themselves.}




\subsubsection{Notification}
Mobile contexts are rife with opportunities for haptic feedback.
Ambient tactile displays \revRG{can provide awareness} and alerts without distracting the user.
\revRG{Because} VT feedback is affordable \revRG{and} low-power, \revRG{it} can be added to watches and wrist-bands \cite{Brunet2013a,Arab2015}, belts, vests, and other wearables.
\osE{Haptic icons \cite{MacLean2003} are analogous to visual icons but transmitted through touch. Tactons \cite{Brown2006} are a type of haptic icon which} provide VT feedback, \eg, in mobile applications.
%Rhythm opens up a large design space, letting users learn 84 different icons \cite{Ternes2008} and can be applied with even light, low-cost rumble motors.
\revRG{Rhythm opens up a large, learnable design space; \citet{Ternes2008} found users could learn up to 84 different rhythmic icons.} %  and can be applied with even light, low-cost rumble motors.}
A 28-day study showed that rhythmic VT icons do not disturb users in daily activities and can communicate ambient information \cite{Cauchard2016}.
\citet{Hemmert2008} explored a life-like metaphor of pulsing and breathing to provide alerts, but found \revRG{that designers needed to take care to not be annoying}.
Multiple actuators can be combined in mobile handheld devices to provide differentiable spatial information, enriching the VT icon design space \cite{Yatani2009a}.
VT icons produced by phones can represent multiple levels of urgency and \revRG{the} source of an alert (\eg, voice call, text message, or multimedia message) \cite{Brown2006mobilealerts}.
\osE{A haptic designer can help select an appropriate notification set \revRG{for diverse} applications in both mobile and non-mobile contexts.}


\subsubsection{Guidance}
Guidance\revRG{, providing directional or timing information,} is a typical application for VT feedback, which can be invisible, mobile, and accessed without using vision or sound.
%Guidance is a major applications, especially for specific populations like the visually impaired \cite{} or older adults \cite{Arab2015}.
Spatial guidance through haptic wearable display can improve navigation with multiple actuators across several form factors, including belts \cite{Pielot2009,Lindeman2005}, wrist-bands \cite{Arab2015}, and vests \cite{Prasad2014}; in each case, the vibrations inform the user where to go with spatial vibrations or metaphorical spatial icons.
Periodic vibrations can guide a user's walking speed without large attentional demands \cite{Karuei2014}.
Tactile illusions like saltation can provide directional information for guidance \cite{Tan1997}; larger back-based displays are effective for guiding both attention and direction, \eg, in automobiles \cite{Tan2003}.
\citet{Brewster2010} used VT icons to provide awareness of nearby friends and colleagues.
%Guidance Linderman2005 \cite{Prasad2014} \cite{Pielot2009}
\osE{Design helps find the right way to guide the user.}





\subsubsection{Education}
Haptic technology has the potential to improve educational resources, especially to those lacking resources.
Montessori methods have long espoused the value of physical learning aids, especially using physical \emph{manipulatives} \cite{Montessori1917}.
There is evidence to support these techniques: in a meta-analysis of 55 studies, \citet{Carbonneau2013} found that physical manipulations improve several learning outcomes, with influence \revRG{from} other instructional variables.
Studies of gestures have also found value in students ``being the graph" by physically acting out mathematical shapes, grounding abstract knowledge in embodied experience \cite{Gerofsky2010}.
These techniques have roots in constructivist learning, where learners use existing understandings as a \emph{transitionary object} to understand new concepts \cite{Papert1980}.

Haptic technology is well-positioned to support embodied learning, and there is early evidence for its efficacy.
Haptic feedback has been shown to improve temporal aspects when training motor skills \cite{Feygin2002}.
In a study for molecular chemistry education, \citet{Sato2008} found students had higher test scores when they interacted with their haptic learning interface; students reported engagement.
In \autoref{ch:applications} we describe results from an early learning interface for low-cost haptic displays \cite{Martinez2016}, showing that haptic technology can improve engagement and make lasting impressions.
\osE{Students can act as designers when learning through creative problem-solving; lessons require carefully designed feedback to engage students without distracting them.}



%\cite{Hook2008bodyemotion} (?)

%Active learning and creativity in education??

%%%%LEARNING
%%%\osC{Education}
%%%Recognition of the value of a hands-on, embodied approach to learning dates to 1907, when
%%%Maria Montessori opened a school where she used \emph{manipulatives} to teach a wide array of concepts ranging from mathematics to reading, e.g., by introducing the alphabet through children tracing their finger along large, cut-out letters~\cite{montessori_advanced_1917}.
%%%Constructivist learning theories posit that well-designed manipulatives can assist understanding by grounding abstract concepts in concrete representations ~\cite{papert1980,piaget_science_1970},
%%%%Their use today is 
%%%and are an accepted core principle in early math and science education, confirmed empirically~\cite{carbonneau_meta-analysis_2013}. 
%%%
%%%More recently, digital technologies are radically altering learning environments.
%%%Massive Open Online Courses (MOOCs) expand access, games motivate, and with graphical simulations (e.g., PhET~\cite{wieman_phet:_2008}), students can interact with abstractions to develop their understanding.
%%%However, these experiences are disembodied. Indirect contact via keyboard, mouse and screen introduces a barrier of abstraction that undermines the connection and path to understanding. 
%%%% that the interaction aims to promote. 
%%%
%%%
%%%Haptic (touch-based) technology should bring %able to bring
%%% benefits of physicality and embodied learning~\cite{dourish_where_2004} to interactive virtual environments. 
%%%It adds a sensory channel as another route to understanding~\cite{calvert_crossmodal_1998}; when deployed appropriately, active exploration can improve understanding~\cite{martin_physically_2005} and memory~\cite{glenberg_activity_2004} of new concepts. 
%%%Haptic tools have already shown promising results in many specializations, demographics and age groups, both
%%%to enhance lesson fidelity 
%%%% (e.g., physics and medical simulations)  -- don't have room for citations!
%%%and to increase engagement and motivation through tangibility and interactivity; e.g., with devices like Geomagic Touch\footnote{Prev. Sensable Phantom \url{www.geomagic.com/en/products/phantom-omni/overview}}~\cite{williams_implementation_2004} and SPIDAR-G~\cite{sato_haptic_2008}.
%%%
%%%Unfortunately, %t
%%%%These 
%%%%Sadly, 
%%%existing approaches have %suffer from 
%%%both hardware and software limitations.
%%%Actuated learning tools introduce physical issues of cost, storage, and breakage;
%%%devices are  too bulky, complex, or expensive for schools or self-learners.
%%%For software, it is hard for users to construct and explore their own haptic environments. Typically, users load a virtual system to interact with it haptically. This sidelines the rich learning potential of involving users with model construction~\cite{papert1980}.
%%%We address hardware with the HapKit~\cite{martinez_2016}, a \$50, simple, low-fidelity device constructed from 3d printed materials.  
%%%
%%%Our focus here is on software, with a new learning environment that lets users both construct and explore haptic systems. Until now, the only way for a user to construct a haptic system was by programming it herself. Our approach, inspired by Logo ~\cite{papert1980} and Scratch ~\cite{maloney2010}, is to ultimately % KM notes: currently we don't provide much power compared to programming. But it's planned for.
%%%provide much of the power of a programming language while hiding distracting complexity. 
%%%



%%%%%%%%%%%%
%
% SECTION: What other inspirations can we draw from? How are we approaching the above-mentioned problem? What scope is reasonable.
%
%%%%%%%%%%%%
\section{Non-Haptic Design and Creativity Tools}
\osE{Design thinking is a process and approach to solving problems.}
\revFinal{Although often used without a definition \cite{Zimmerman2007rtd}, design thinking always involves rapidly generating and evaluating multiple ideas, and iteratively exploring a problem space by articulating and manifesting a solution space; ideas then converge to a final developed concept (or set of concepts) \cite{Buxton2007}}.
Design is increasingly studied as a field in non-haptic contexts, providing both guidelines and inspiration for \haxd.
In this section, we present related work on \osE{general design thinking} organized into three major elements: problem preparation, hands-on design, and collaboration.
\revFinal{We then briefly discuss the relationship between design and research.}

\subsection{Problem Preparation}
Creative tasks, like design, are often defined as the recombination of existing ideas, with a twist of novelty or spark of innovation by the individual creator \cite{Warr2005}.
Also known as the ``problem setting" \cite{Schon1982}, ``analysis of problem" \cite{Warr2005}, or ``collect" \cite{Shneiderman2000} step, problem preparation involves getting a handle on the problem,  drawing inspiration from previous work. %, and and establishing a first general approach with which to attempt a solution.
Sch\"{o}n demonstrated that designers initially frame their problems before developing a solution \cite{Schon1982};
he also describes the designer's repertoire, their collected experience, which aids in design.
External examples are especially useful for inspiration and aiding initial design \cite{Herring2009,Buxton2007}. 
In our work, the design activity of \emph{browse} overlaps significantly with problem preparation.

%%Framing, finding the appropriate metaphor for thinking about the problem \cite{Schon1982}.
%When encountering a new problem, a designer begins \emph{framing}, finding the appropriate metaphor for thinking about the problem, typically drawn from her experience.
%In this way, metaphors that people already understand can be used to learn about new situations as a transitionary object \cite{Papert1980}.
%%Framing involves transforming the problem so that the designer can get a handle on it and begin to make progress.
%\emph{Framing} could involve a set of constraints upon the design problem, a list of requirements, or notational language to describe the problem.
%The more we can say about the problem, the more we can make progress on the solution.
%
%When \emph{framing}, designers draw from a \emph{repertoire} of their own previous experience that guides their design, storing cases, images, understandings, and actions \cite{Schon1982}.
%This approach is widespread in the haptics literature (e.g., ``haptic icons"  \cite{MacLean2003}, ``touch TV" \cite{Modhrain2001}), suggesting that we often have to rely on outside metaphors to describe concepts in haptics.
%
%Designers draw both from their \emph{repertoire} and from others' design \emph{examples}.
%While other sources sometimes use ``example" to refer to previously-encountered case studies \cite{Schon1982}, we consider those as part of the \emph{repertoire} and use ``example" exclusively to refer to externalized resources.
%In other fields of design, designers clip, store, and display \emph{examples} for inspiration \cite{Buxton2007} (\autoref{fig:corkboard}).
%Industrial designers collect various knobs and materials, and web designers bookmark sites \cite{Herring2009}.
%Managing these \emph{examples} effectively is already a significant task even in these more visual fields.
%%; with haptics, which often involves both software and hardware, this becomes a serious barrier.
%To work effectively with \emph{examples}, we need to have ways to capture, visualize, and recall them \cite{Herring2009}.

\subsection{Hands-On Design}
%There has recently been a shift in how we interpret the act of thinking.
%No longer is t
\osE{Thinking is not} relegated to the head, \osE{but} situated in the physical world \cite{Hutchins1995}.
The designer must iteratively generate a varied set of initial ideas  (ideation) and then prune them (evaluation), repeating this step many times to settle on a single design \cite{Buxton2007}.
Working with multiple ideas simultaneously is a boon to good design.
Developing interfaces in parallel can facilitate generation and evaluation, delaying commitment to a single design \cite{Hartmann2008, Resnick2008}, while
in groups, sharing multiple designs improves variety and quality of designs \cite{Dow2011}.


Sketching supports ideation, evaluation, and multiple ideas,
allowing the designer to
explicitly make moves in a game-like conversation with the problem \cite{Schon1982}.
It is so important that some researchers declare it to be the fundamental language of design, like mathematics is \revRG{said to be} the language \revRG{of} scientific thinking \cite{Cross2006}.
The power of sketching, according to Cross, is contained in its ability to describe a partial model of a proposed design or problem.
Detail can be subordinated, allowing a designer to zoom-in, solve a problem, and then
abstract it away when returning to a high-level view.
%\osC{cut this paragraph - should some of it be incorporated?}
This has implications for software tools: designers must easily navigate the design space with undo, copy and paste, and a history of progress, creating tools with a ``high ceiling" and ``wide walls" \cite{Resnick2008}.
We use the term ``sketching" in a broad sense, including both pencil and paper and software or hardware sketches \cite{Moussette2010,Buxton2007}.
Our design activity of \emph{sketching} refers to exploration and demonstration as distinguished from iterative \emph{refinement}.
In other works, sketching can encompass iteration, annotation, and some level of refinement.

\subsection{Collaboration}
Design is a collaborative process\osE{.}
\osE{Working in groups has} the potential for generating more varied ideas \cite{Warr2005} \osE{than working individually}, and is important for creativity support tools \cite{Resnick2008,Shneiderman2000}.
Although sometimes group dynamics influence the design process negatively, proper group management and sharing of multiple ideas results in more creativity and better designs \cite{Herring2009}.
Shneiderman in particular has championed collaboration in design \cite{Shneiderman2000}, and suggests two different types of collaboration to be supported by creativity tools: relating, informal discussions with colleagues, and donating, disseminating information to the public/annals of time.
Orthogonal to these intended purposes (relating and donating) is the collaboration context.
Computer-supported collaborative work often separates interactions into four contexts ordered into two dimensions: collocated (same location) or distributed (different locations), and synchronous (simultaneous)  or asynchronous (at different times) \cite{Ellis1991}.
\osE{This distinction is useful for scoping challenges facing \haxd: touch is proximal and context-dependent, inhibiting asynchronous and remote collaboration.}
%Collaboration is notable because it is inherently challenging to haptic design: two people can look at the same image or hear the same sound from across a room, but touch is a local sense, far easier in a collocated, synchronous setting.
We explore informal collaboration briefly in \autoref{ch:hapticinstrument}, and explore \osE{aspects} of \emph{sharing} in more detail in Chapters \ref{ch:hapturk} and \ref{ch:applications}.
\autoref{ch:hapticianinterviews} characterizes how professional haptic designers collaborate.


\subsection{\revFinal{Design Research}}
\revFinal{
The HCI community is actively exploring the relationships between design and research.
Both are intertwined for interactive systems.
Current discourse revolves around how HCI research can draw knowledge from design methods, and how knowledge gained from research can inform design practice.
}

\revFinal{
\citet{Frayling1993research} challenges popular stereotypes about design, art, and scientific research. 
He suggests three different different relationships: research \emph{into} design (and art), research \emph{through} design, and research \emph{for} design.
Research into design is common, including historical research, aesthetic or perceptual research, and perspectives or theories about design.
Research for design is ``small 'r'" research, and includes the gathering of reference materials, examples, and previous artifacts to support the design of a product or experience, not for knowledge creation.
Research through design (RtD) involves practicing design with the explicit goal of creating research, including materials research by creating artifacts, customizing or developing technology, or action research.
}

\revFinal{
\citet{Zimmerman2007rtd} suggests RtD as a model to involve design into HCI research.
Designers can be involved in knowledge-making by attempting to "make the right thing."
Knowledge is embedded into artifacts and the process of their creation, integrating both ``true" and ``how" knowledge.
To develop RtD into a more formal methodology, \citet{Zimmerman2010} conducted interviews with leading HCI design researchers and found that design projects in a research context can serve as a common vocabulary between researchers and inspiration for future projects.
\citet{Gaver2012researchthroughdesign} points out that RtD fits into scientific paradigms by supporting theory development, but cautions against too much formalization of this methodology.
Instead, Gaver argues that diversity of design approaches is a virtue, and that annotated portfolios may uphold design's advantages while providing reusable knowledge.
}

\revFinal{
Consistently, design is proposed as a means to progress solving ``wicked problems" \cite{Rittel1973dilemmas}.
The core value of design in research is its ability to resolve between these ill-posed problems and potential solution spaces.
Sketching and prototyping remain core techniques to interactively have a dialogue with a problem \cite{Schon1982}, but this can happen when design embedded within a research context: ``design-oriented research")\cite{Fallman2003designoriented}.
In this dissertation, we use RtD to explore the problem space of creating \haxd support tools (Chapters 3-6), and in practicing \haxd as a designer (Chapter 7). 
}

% (\autoref{tab:groupware}).
%Considering these different contexts illuminates specific goals when supporting haptic experience design.

%\begin{figure}[tbp] %  figure placement: here, top, bottom, or page
%   \centering
%   \includegraphics[width=0.33\textwidth]{figures/CollaborateSubProcesses2} 
%   \caption{Collaboration sub-activities. Designers work collaboratively in a continuum between \emph{donating}, \emph{relating}, and gathering \emph{feedback}.}
%   \label{fig:collaborate:sub:activities}
%\end{figure}

%\subsection{Challenge - Distributed Haptics}

%However, collaboration in the remote or asynchronous case is more challenging.
%Haptics has long been examined in remote collaboration both with force feedback \cite{Kim2004} and tactile \cite{Chan2008} mechanisms.
%Remote collaboration to support haptics, on the other hand, is a different beast.

%\subsubsection{Asynchronous collaboration}
%Collocated collaboration is common and well supported in haptics.
%In the synchronous case, \emph{relating} is a common activity, e.g., getting labmates and visitors to quickly try a prototype. User studies typically occur
%face-to-face as well, and 
%demonstrations at conferences \emph{donate} haptics to the community (indeed, the haptics community prioritizes demos so much that the inaugural Asia Haptics conference in 2014 was entirely in demo format).
%Asynchronous collaboration is less typical, with special advantages and issues.
%More investigation into asynchronous collaboration could reap rewards of self-running demos and user studies that collect copious data from diverse deployments % result in self-running demos and user studies that collect large amount of data from diverse populations (by deployment into different areas) 
%at low time cost to HaXD practitioners.
%%While more formal activities like feedback or donation could also be imagined , asynchronous collaboration is \kmC{get more specific : poorly understood}.
%%(self-running user studies or tactile installations \cite{Laaksolahti2011})

%\subsubsection{Distributed collaboration}
%Working remotely is even more challenging, both for synchronous and asynchronous contexts.
%Haptics involves physical devices and is a proximal sense.
%When working at a distance, there must be two identical devices.
%This means all components must be identical, whether electrical (e.g., amplifier settings), mechanical (e.g., joint dampening), or software.
%
%Distributed \textit{relating} can be supported in some small-scale cases.  % because of the small scale of devices.
%Each colleague could have a calibrated, identical device with synchronized software.
%% Because each colleague is expected to be 
%When each collaborator is knowledgeable about the device, video chat and email could provide sufficient support for many applications.
%Devices can be shipped or fabricated and calibrated at each location.
%While this introduces delay, slowing iteration and adding communication overhead, it is achievable.
%






%%%%%%%%%%%%
%
% SECTION: Why should we care about haptic experience design tools? What is the precise problem this dissertation is solving?
%
%%%%%%%%%%%%
\section{Previous Efforts for Haptic Experience Design}
We are not the first to look into haptic media production or to apply design thinking to haptic design.
While we present a cohesive look on \haxd process linked to general guidelines for \haxd support tools, previous work has developed \osE{interactive software} tools, supportive software and hardware platforms, and conceptual frameworks to facilitate \haxd.


\subsection{\osE{Interactive Software Tools}}
As long as designers have considered haptic effects for entertainment media, they have needed compositional tools % to facilitate their design 
\cite{Gunther2002}.
\osE{Here, we report on interactive software tools for editing haptic sensations.}


\subsubsection{\osE{Track-based editors}}
Many user-friendly interfaces help designers create \osE{haptic effects}.
The Hapticon editor \cite{Enriquez2003}, Haptic Icon Prototyper \cite{Swindells2006}, and posVibEditor \cite{Ryu2008} use graphical mathematical representations to edit either waveforms or profiles of dynamic parameters (torque, frequency) over time.
\osE{H-Studio \cite{Danieau2013c} enables editing of multi-DOF force feedback for video.}
\osE{A less orthodox approach is t}he Vibrotactile Score \cite{Lee2009}\osE{, which uses musical notation. The Vibrotactile Score was} shown to be generally preferable to programming in C and XML, but required familiarity with musical notation \cite{Lee2012}.
\osE{In industry, editors like the D-Box Motion Code Editor overlay} visual and audio content with haptics, and allow designers to generate, tune and save frame-by-frame haptic content. 
Vivitouch Studio allows for haptic prototyping of different effects alongside video (screen captures from video games) and audio, and supports features like A/B testing \cite{Swindells2014}.
\osE{While most existing editors focus on vibration effects or simple forces, other types of actuation are now receiving attention, \eg, the Tactile Paintbrush creates friction profiles for the TPad \cite{Meyer2016}.}



\subsubsection{\osE{Mobile Design Tools}}
Mobile tools make haptic design more accessible.
The Demonstration-Based Editor \cite{Hong2013} allows control of frequency and intensity by moving graphical objects on a touchscreen.
%mHIVE, a Haptic Instrument \cite{Schneider2014} controls frequency, intensity, waveform and amplitude envelope of two tactors with touchscreen gestures.
Similar to the SPIN lab's Haptic Instrument (mHIVE, \autoref{ch:hapticinstrument}), this mobile tool was shown to be intuitive and easy to use for exploration or communication, but faltered when refining more elaborate sensations. %for a set context.
Commercially, Apple's end-user vibration editor has been present in iOS since 2011 (iOS 5) but only produces binary on/off timing information\osE{;}
Immersion Touch Effects Studio lets users enhance a video from a  library of tactile icons on a mobile platform.


\subsubsection{\osE{Automatic Generation}}
One approach is to use camera motion sourced from accelerometers \cite{Danieau2012} to actuate audience members' hands and head in a HapSeat \cite{Danieau2013a,Danieau2012a}.
Several studies have looked into automatic conversion from audio streams \cite{Lee2013,Chang2005,Hwang2014} or video streams \cite{Kim2014} to VT or force-feedback output.
\osE{Automatic techniques can be combined with later editing to populate a design before a designer works with it.}

\subsubsection{\osE{Multi-actuator Tools}}
The control of multi-actuator outputs has been explored by TactiPEd \cite{Paneels2013}, Cuartielles' proposed editor \cite{Cuartielles2012}, and the tactile movie editor \cite{Kim2009}; the latter combined spatial and temporal control using a tactile video metaphor for dense, regular arrays of tactile pixels (``taxels"), including a feature of sketching a path on video frames. 
However, these approaches embrace the separate control of different actuators, rather than a single perceived sensation produced by the multi-actuator device, which we address with tactile illusions in \autoref{ch:tactileanimation}.

%The hapticon editor \cite{Enriquez2003}, haptic icon prototyper \cite{Swindells2006}, posVibEditor \cite{Ryu2008}, and Immersion's Haptic Studio (www.immersion.com) use a graphical representation to edit either waveforms or profiles of dynamic parameters (such as, torque) over time.

%Both emphasize exploration and broad manipulation rather than finely controlled end results.


\subsection{Platforms}
\osE{Prototyping platforms help users rapidly build haptic effects.}
\osE{We first report software platforms, then hardware.}

\subsubsection{\osE{Software Libraries}}
There are many software libraries to support developers.
\osE{Some are collections of effects available to designers.}
The UPenn Texture Toolkit contains 100 texture models created from recorded data, rendered through VT actuators and impedance-type force feedback devices \cite{Culbertson2014}.
The HapticTouch Toolkit \cite{Ledo2012} and Feel Effect library \cite{Israr2014} control sensations using semantic parameters, like ``softness" or ``heartbeat intensity" respectively.
%and Feel Effects  provide examples for vibrotactile actuators, like those found in game controllers and mobile devices.
\osE{VibViz is an online tool organizing 120 vibrations into perceptual facets \cite{Seifi2015}.}
Vibrotactile libraries like Immersion's Haptic SDK (immersion.com) connect to mobile applications, augmenting Android's native vibration library.
%FeelCraft's plugin architecture connects feel effects to various media types \cite{SchneiderAsiaHaptics2014}.
\osE{Collections of effects can help a designer start their design, but few are open and modifiable, which we establish as a valuable feature in \autoref{ch:macaron}.}

\osE{Other software libraries facillitate programming.}
Force feedback devices have \osE{mature APIs} like CHAI3D (chai3d.org), H3D (h3dapi.org), and OpenHaptics (geomagic.com). 
Immersion's TouchSense Engage is a software solution for \osE{vibration feedback for} developers.
The Haptic Application Meta Language (HAML) \cite{Eid2006} is an XML-based data format for adding haptics to MPEG-7 video, eventually augmented with the HAML Authoring Tool (HAMLAT) \cite{,Ferre2008}.
\citet{AbdurRahman2010} adapted an XML approach to YouTube, and \citet{Gao2013} developed related online MPEG-V haptic editing.
\osE{Programming is extremely flexible, but are abstract; designers are usually not be able to feel what they design.}

\subsubsection{\osE{Hardware Prototyping Platforms}}
Hardware prototyping platforms \osE{speed physical development.}
Arduino (arduino.cc) \osE{is a popular} open source microcontroller % platform 
and development platform \osE{with a dedicated editor}.
Phidgets (phidgets.com) facilitate rapid hardware prototyping with over 20 programming languages 
\cite{Greenberg2001}.
More recently, Wooden Haptics gives open-source access to fast laser cutting techniques for force feedback development \cite{Forsslund2015}.
These platforms, especially Arduino, have made significant improvements to enable rapid iteration and hardware sketching.
\osE{W}e can do better: these platforms require programming, hardware, and haptics expertise, and include inherent time costs like compilation, uploading, and debugging.



\subsection{Conceptual Tools}
\osE{Design can be supported by having a good metaphor to frame it.}
\osE{Here, we report on different ways to approach a haptic design: higher-level perspectives, metaphors for designers, and the language of touch.}

\subsubsection{\osE{Perspectives}}
Some higher-level perspectives offer outcome targets or design attitudes to guide haptic practitioners.
``DIY Haptics'' categorize  feedback styles and design principles \cite{Hayward2007,MacLean2008}.
``Ambience'' is proposed as one target for a haptic experience \cite{MacLean2009}.
Haptic illusions can serve as concise ways to explore the sense of touch, explain concepts to novices and inspire interfaces \cite{Hayward2008}.
``Simple Haptics'', epitomized by \emph{haptic sketching}, emphasizes rapid, hands-on exploration of a creative space \cite{Moussette2010,Moussette2011}. % with a design perspective \cite{Moussette2010,Moussette2011}.
Haptic Cinematography \cite{Danieau2014} uses a film-making lens, discussing physical effects using cinematographic concepts.
%The notion of distributed cognition \cite{Hutchins1995} has particular relevance for haptic design, % provides an important perspective for haptic design in particular, 
%suggesting that people situate their thinking both in their bodies and in the environment.
Haptics courses are taught with a variety of \osE{pedagogical} viewpoints, including perception, control, and design\osE{; they provide} students with an initial repertoire of skills \cite{Okamura2012, Jones2014}.

\subsubsection{\osE{Metaphors for design}}
Haptics has often made use of metaphors from other fields.
Haptic icons  \cite{MacLean2003}, tactons \cite{Brewster2004}, and haptic phonemes \cite{Enriquez2006} are small, compositional, iconic representations of haptic ideas.
Touch TV \cite{Modhrain2001},  tactile movies \cite{Kim2009}, haptic broadcasting \cite{Cha2009}, and Feel Effects \cite{Israr2014} attempt to add haptics to existing media types, especially video.
Haptic Cinemotography \cite{Danieau2013,Danieau2014} uses a film-making lens for haptic-augmented multimedia, including basic principles of composition when combined with video \cite{Guillotel2016}.


Musical analogies have frequently been used to inspire haptic design tools, especially VT sensations. %unique.
The Vibrotactile Score, a graphical editing tool representing vibration patterns as musical notes, is a major example \cite{Lee2012, Lee2009}.
%The vibrotactile score provides an abstraction beyond low-level parameters and can draw from a musician's familiarity with the notation.
Other musical metaphors include the use of rhythm, often represented by musical notes and rests \cite{Ternes2008,Brown2005,Chan2008, Brown2006a}.
Earcons and tactons are represented with musical notes \cite{Brewster1993,Brewster2004}, complete with
tactile analogues of crescendos and sforzandos \cite{Brown2006}.
The concept of a VT concert found relevant tactile analogues to musical pitch, rhythm, and timbre for artistic purposes \cite{Gunther2002}.
Correspondingly, tactile dimensions have been also been used to describe musical ideas \cite{Eitan2010}.
\osE{Though music lends its vocabulary to touch, non-temporal properties remain difficult-to-describe.}


%\subsection{Language of Tactile Stimuli}
\subsubsection{\osE{Language of Touch}}
The language of tactile perception, especially affective (emotional) terms, is another way of framing haptic design.
%The language of tactile stimuli has a long history in psychological studies \cite{Okamoto2013}.
Many psychophysical studies have been conducted to determine the main tactile dimensions with both synthetic haptics and real-world materials  \cite{Enriquez2003,Okamoto2013}.
Language is a promising way of capturing user experience \cite{Obrist2013}, and can reveal useful parameters, e.g., how pressure influences affect \cite{Zheng2012}.
Tools for customization by end-users, rather than expert designers, are another way to understand perceptual dimensions \cite{Seifi2014, Seifi2015}.
However, this work is far from complete; touch is difficult to describe, and some even question the existence of a tactile language \cite{Jansson-Boyd2011}.
\osE{In this dissertation, we encounter the language of touch in some chapters (\autoref{ch:hapticinstrument}, \autoref{ch:hapturk}).}
\osE{However, we approach our design tools without an imposed language, giving designers fast, powerful control over low-level parameters like frequency and amplitude.}
%There is a clear need to empirically investigate the subjective experience of touch-based interfaces, for which phenomenology is ideal \cite{Creswell2013, Moustakas1994}.
%Start with hapticons, tactons, vibrotactile icons, Earcons, Auditory icons...
%Participants described two different sensations, one oscillating at 16 Hz and the other at 250 Hz.





%%%%%%%%%%%%
%
% SECTION: Methodology. How will we transform the above-mentioned approach into knowledge? How can we study our solutions?
%
%%%%%%%%%%%%
\section{Methodology}
We used a mixed-method approach to the work presented in this dissertation.
We combined \revFinal{research through design} with qualitative and quantitative analysis to gather complementary information.
The particular blend of methods depended on \revRG{the} project. %each project.}
%Studying design process, creativity support tools, and haptic sensations is challenging and requires a robust methodology.
%We use mixed methods to explore our research questions of process, strategies, and experience.
%As we have seen in our discussion of creativity and design support, systems of creativity tools are complex and noisy.
We began with design and qualitative techniques to gather rich, generative data from design tools. %and design processes, and to inform iteration.
We then iteratively refined our qualitative methods, and built towards large-scale data collection for our generated theories with quantitative analysis and deployed tools.
%Furthermore, this work is an early inquiry requiring inductive models of thinking to generate theories, and the flexibility to accommodate invention as part of the inquiry, \eg letting us build tools iteratively based on participant feedback.
%As such, we turn to qualitative methodologies first and foremost, and as we gather findings, we gradually apply more hypothesis-testing-based approaches in a quantitative tradition.


\revFinal{We began our research process using research through design \cite{Zimmerman2007rtd}.
Beginning with design allowed us to iteratively frame our questions \cite{Zimmerman2010} while generating initial theories \cite{Gaver2012researchthroughdesign}.}
%We took a design approach to understanding \haxd.
%Prototypes manifest design ideas \cite{Lim2008}.
\revFinal{In addition, b}y building usable support tools, we gained direct knowledge of how to work haptic devices.
A design approach is constructive;
working tools exactly specify design ideas, can be shared with haptic designers as a practical contribution, and provide an extendable platform to facillitate future research.
For example, implementing Tactile Animation informed how to architect Macaron, which we could then directly extend as MacaronBit (\autoref{sec:applications:cuddlebit})
% letting us easily follow up on subsequent research questions.


\osE{
Qualitative research methods let us \revRG{study complex} phenomena in flexible, rigorous way.
They are generative, supporting building a hypothesis from observations with few theoretical assumptions.
Qualitative frameworks support diverse, rich data, including observational findings, interview, and screen-captured video.
This data helped us capture the experience of \haxd and develop guidelines for iteration on our tools' early implementations.
We drew from two methodologies in our qualitative studies: phenomenology and grounded theory.
}

%In this dissertation, we draw from the philosophical and methodological traditions of phenomenology, and the methodology of grounded theory.
Phenomenology is both a philosophical tradition and a social science methodology based upon that tradition that involves the study of subjective experience.
We used \citet{Moustakas1994} as our primary guide through both, as it focuses on practical methodological concerns but provides a strong philosophical background; \citet{Creswell2013} provided an overview of various methodologies and resources for phenomenology.
%Critical components include \emph{horizonalization}, or preparing oneself to consider all of the participant's statements equally and with fresh eyes; distinguishing and synthesizing \emph{textural} descriptions, \eg the participant's verbatim explanation of the experience, with \emph{structural} description, or the analytical interpretation through psychology (or HCI) theories; and the documentation of the researcher's own experience with the phenomenon of study.
Phenomenology as a methodology has been used in psychology to investigate topics ranging from visual illusions to tactile experience \cite{Richer1978, Obrist2013, Creswell2013}.
%Methodologies, like phenomenology, often include a set of methods combined with their philosophical and epistemological underpinnings.
In this work, we specifically use the Stevick-Colaizzi-Keen methods as described by \citet{Moustakas1994}.
\osE{This technique handles textual data: t}ranscripts are divided into non-overlapping, non-redundant statements about the phenomenon known as Meaning Units (MUs).
%This considers every statement that the participants make, and does not discount any due to bias or selective searching.
MUs are then clustered into emergent themes through affinity diagrams, writing and re-writing of thematic descriptions, and reflection guided by phenomenological philosophy.
%We use this technique exactly in o
%\osE{O}ur first exploratory study (\autoref{ch:hapticinstrument}) \revFinal{drew primarily from} phenomenology. 
\revFinal{Because \haxd is not a commonly experienced phenomenon, we drew from phenomenological methods to examine the limited experiences of in-lab stimuli.
This approach is similar to previous work on sensory perception, \eg, geometric illusions \cite{Richer1978}, or mid-air tactile displays \cite{Obrist2013}.
In our case, we studied the experience of design haptic sensations using our provided design tools.
}

Grounded theory is another well-known methodology first described by \citet{glaser1966awareness}.
We adopted the more flexible methodology described by \citet{Corbin2008}, as it allowed us to integrate with our phenomenological methods.
We principally adapted the methods used in grounded theory, specifically, memoing (writing about each focused quotation), constant comparison (comparing each new memo and codes to previous ones), and open and axial coding (creating codes, or concepts, linking them together, then categorizing statements or observations based on codes).
These techniques facillitated video analysis in \autoref{ch:tactileanimation} and \autoref{ch:macaron}, and allowed for quantitative count-based data and simple statistics to complement our interview-based findings.
\revFinal{\autoref{ch:SupportingMaterials:MethodExamples} provides examples of intermediate products from analysis in \autoref{ch:macaron}.}

%We also note that researchers who use methods from the umbrella term ``qualitative research" often blend techniques from many methodologies.
%Phenomenology and grounded theory are two such methodologies, others include hermeneutics, ethnography \cite{Moustakas1994}, ethnomethodology, and thematic analysis \cite{Ryan2003}.
%For example, ethnography introduces the concept of ``thick description" \cite{}, where the research tries to use detailed, evocative language to convey a rich sense of being in the observed environment.
%This technique is used more generally in observational notes and when writing up qualitative results to provide the rich data studied by qualitative methods.

While some design scholars \osE{employ} qualitative techniques \cite{Schon1982,Cross2007,Cross2011}, others have developed quantitative techniques.
\osE{Statistical analysis and other quantitative methods can analyze large data sets and complement qualitative research questions.}
When studying graphic design for ads, \citet{Dow2011} used ratings by experts as well as click-through rates and other online analytics for actual deployed ads from their study.
\citet{Kulkarni2014} used MTurk to generate sketches of aliens in several conditions (of exposure to examples), then deployed another MTurk task to label each drawing with features like antennae or feet.
\citet{Lee2010a} had end-users rate graphic designs in both an in-lab study and over Mechanical Turk, and recorded time participant designers spent on each component.
%These approaches allow for hypothesis testing for specific research questions, but require infrastructure unavailable to haptics, notably, crowd deployment, rating scales, and mature input tools.
%In our early work, we found qualitative feedback to be sufficient while developing our understanding of how to build design tools.
\osE{Large-scale online studies are currently not available for haptic technology, which requires data collection infrastructure.}
\osE{As we started to use quantitative data, we also began to build this infrastructure} using an online editor with analytic logs in Macaron (\autoref{ch:macaron}) and examining the potential for crowdsourced feedback with HapTurk (\autoref{ch:hapturk}).
While a valuable goal, large-scale quantitative feedback on \haxd remains outside the scope of this dissertation.

%%%%Unfortunately, these approaches do not scale to %\kmC{slc} % KM: seems like references to 'feedback' 'donate' etc should all be italicized because of their special sense.
%%%%formal \emph{feedback} or wide-spread \emph{donate tasks}, which typically have a large or anonymous audience with diverse % limited 
%%%%resources.
%%%%A wide-spread standardized device platform could support distribution, but given the variety of haptic effects \cite{Hayward2008}, this is extremely limiting and would tend to enforce a `lowest common denominator' effect.
%%%%Without assuming standardization, we suggest two possible solution strategies, each with tradeoffs:
%%%%accessible fabrication and device generalization.
%%%%
%%%%Fabrication methods like 3D printing are increasingly accessible. % to end-users.
%%%%%At a recent meeting with collaborators conducting 3D printing of haptic devices to a wide spread 
%%%%%\kmC{slc} % KM: following sentence confuses me, does it follow from 1st? Should there be a 'however"? Why does the complexity of haptic device manufacture fit it best for asynchronous collab - wouldn't that be better for synchro + collocated? 
%%%%However, manufacturing haptic devices is
%%%%complex, with software, moving parts,  and electronics, often requiring some assembly, best suited for asynchronous collaboration.
%%%%Furthermore, there is no guarantee that users have assembled their devices correctly.
%%%%Collaborators at a recent workshop found it difficult to verify % noted the difficulty in verifying 
%%%%system dynamics on their kit-based device in an asynchronous \textit{donate} task.
%%%%A resulting brainstorm \emph{ideated} a small calibration element to capture system dynamics, and a suite of diagnostic checks to help devices be consistent (e.g., template virtual environments with described ``correct behaviour").
%%%%%One promising area for investigation is in calibration tools to ensure remote devices are operating in similar fashion.
%%%%More advanced fabrication techniques may be able to improve this problem, producing moving parts, electronics, or other essential components.
%%%%
%%%%A second approach is to not attempt identical devices, but ensure they communicate what needs communicating.
%%%%We define device generalization in haptics as \emph{consistently reproducing intentional aspects of a haptic sensation}.
%%%%For example, a user watching a video of a force-feedback device on their phone could feel the force vector magnitude as vibration intensity (a \emph{donate} task), or a video chat could be augmented with a virtual environment rendered on force-feedback devices with different complexity.
%%%%This approach relies on partial standardization -- some sort of infrastructure is in place that facilitates constant output, for example, haptic broadcasting \cite{Cha2009}, touch TV \cite{Modhrain2001}, cinematography \cite{Danieau2014}, and tactile movies \cite{Kim2009}.
%%%%This is a challenging area, full of cross modal effects and contextual considerations (how is the user holding their phone?).
%%%%However, we think this is a promising approach while fabrication develops, especially for a \emph{donate} task in both synchronous and asynchronous interactions.
%%%
%%%
%%%
%%%
%%%\osC{SLC for HapTurk RW}
%%%%\section{Related Work}
%%%%We cover work related to VT icons and evaluation methods for VT effects, the current understanding of affective haptics, and work with Mechanical Turk in other modalities.
%%%%   %% \subsection{VT Icons}
%%%%     
%%%%		%%[change first sentence] VT effects are useful. According to previous studies, VT icons can communicate information [ref] and affect [ref]. VT effects are developed to assist visually-impaired users in outdoor scenarios [ref] as well as accessing digital information [ref]. In addition, VT effects can increase performance on visual interfaces, enhance engagement with the content and provide better user experience with electronic devices [ref to levesque].
%%%%		
%%%%\subsection{Existing Evaluation Methods for VT Effects} 
%%%%
%%%%The haptic community has appropriated or developed many types of user studies to evaluate VT effects and support VT design.
%%%%These target a variety of objectives:
%%%%
%%%%1) {\em Perceptibility:} Determine the perceptual threshold or Just Noticeable Difference (JND) of VT parameters. Researchers vary the values of a VT parameter (e.g., frequency)
%%%%% in small steps
%%%%to determine the minimum perceptible change
%%%%%for the parameter
%%%%~\cite{JNDstudy,foundationsoftactile}. 
%%%%
%%%%2) {\em Illusions:} Studies investigate effects like masking or apparent motion of VT sensations, useful to expand a haptic designer's palette \cite{Hayward2008,Israr2011a,Seo2013}.
%%%%
%%%%3) {\em Perceptual organization:} Reveal the underlying dimensionality of how humans perceive VT effects (which are generally different than the machine parameters used to generate the stimuli).
%%%%Multidimensional Scaling (MDS) studies are common, inviting participants compare or group vibrations based on perceived similarity~\cite{Hollins93,van2003distilling,Pasquero2006,Chan2008,Ternes2008}.
%%%%
%%%%4) {\em Encoding abstract information:} Researchers examine salient and memorable VT parameters (e.g. energy, rhythm) as well as the number of VT icons that people can remember and attribute to an information piece~\cite{Brown2006a,Allen2005,Chan2008,Ternes2008}.
%%%%
%%%%5) {\em Assign affect:} Studies investigate the link between affective characteristics of vibrations (e.g., pleasantness, urgency) to their engineering parameters (e.g., frequency, waveform)~\cite{Ternes2008,affect2015,Raisamo,Koskinen}.
%%%%To achieve this, VT researchers commonly design or collect a set of vibrations and ask participants to rate them on a set of qualitative metrics.
%%%%
%%%%6) {\em Identify language:} Participants describe or annotate tactile stimuli in natural language~\cite{Chan2008,Ternes2008,Obrist2013,Guest2011,Hwang2011,Seifi2015}.
%%%%
%%%%7) {\em Use case support:} Case studies focus on conveying information with VT icons such as collaboration~\cite{Chan2008}, public transit~\cite{Brunet2013a} and direction \cite{Brunet2013a,Arab2015}, or timing of a presentation~\cite{presentationtiming}. In other cases, VT effects are designed for user engagement, for example in games and movies, multimodal storytelling, or art installations~\cite{Israr2014,feelcraft}. 
%%%%Here, the designers use iterative design and user feedback (qualitative and quantitative with user rating) to refine and ensure effective design.
%%%%
%%%%All of the above studies would benefit from the large number of participants and fast data collection on MTurk.
%%%%In this paper, we chose our methodology so that the results are informative for a broad range of these studies.
%%%%
%%%%\subsection{Affective Haptics}
%%%%VT designers have the challenge of creating perceptually salient icon sets that convey meaningful content. A full range of expressiveness means manipulating not only 
%%%%a vibration's physical characteristics but also its perceptual and %affective
%%%%emotional properties, and collecting feedback on this. Here, we refer to all these properties as affective characteristics. 
%%%%
%%%%%;then, based on Multi-Dimensional Scaling... to 
%%%%%(New sentence)Using Multi-Dimensional Scaling (MDS) analysis of similarity ratings, it was proposed... (the same)
%%%%Some foundations for affective VT design are in place. Studies on tactile language and affect are establishing a set of perceptual metrics~\cite{Obrist2013,Seifi2015}. Guest \etal\ collated a large list of emotion and sensation words describing tactile stimuli; then, based on multidimensional scaling of similarity ratings, proposed comfort or pleasantness and arousal as key dimensions for tactile emotion words, and rough/smooth, cold/warm, and wet/dry for sensation~\cite{Obrist2013}.
%%%%Even so, there is not yet agreement on an affective tactile design language~ \cite{Jansson-Boyd2011}.
%%%%
%%%
%%%%
%%%% THIS PART MAY BE INCLUDED ALREADY IN ch:hapturk
%%%%
%%%%%Recently, Seifi \etal\ compiled research on tactile language into five taxonomies for describing vibrations~\cite{Seifi2015}.  \textbf{1) Physical properties} that can be measured: e.g., duration, energy, tempo or speed, rhythm structure; 
%%%%%\textbf{2) sensory properties}: roughness, and sensory words from  Guest \etal's touch dictionary \cite{Guest2011};
%%%%%\textbf{3) emotional interpretations}: pleasantness, arousal (urgency), dictionary emotion words \cite{Guest2011};
%%%%%\textbf{4) metaphors} provide familiar examples resembling the vibration's feel: heartbeat, insects;
%%%%%\textbf{5) usage examples} describe % types of 
%%%%%events which a vibration fits: an incoming message or alarm.
%%%%%
%%%%%%addressing Karon's comment a bit 
%%%%%%To evaluate our vibration proxies, we derived the five most salient metrics from these taxonomies. 
%%%%%To evaluate our vibration proxies, we derived six metrics from these taxonomies to capture vibrations' physical, sensory and emotional aspects:  
%%%%%1) duration, 2) energy, 3) speed, 4) roughness, 5) pleasantness, and 6) urgency. 
%%%%%% \kmC{why these 5? you took one from each taxonmy, but why this particular one?}
%%%%%
%%%%%
%%%%%\subsection{Mechanical Turk (MTurk)}
%%%%%
%%%%%\purple{Crowdsourced studies have drawbacks. The  remote, asynchronous study environment is not controlled; compared to a quiet lab, participants may be subjected to unknown interruptions, and may spend less time on task with more response variability~\cite{mutrkgeneral}.
%%%%%MTurk is not suitable for getting rich, qualitative feedback or following up on performance or strategy~\cite{behavioralturk}. Best practices -- e.g., simplifying tasks to be confined to a singular activity, or using instructions complemented with example responses -- are used to reduce task ambiguity and improve response quality~\cite{Amazon.comInc.2015}.
%%%%%Some participants try to exploit the service for personal profit, exhibiting low task engagement~\cite{Downs2010}, and must be pre- or post-screened.} 
%%%%%
%%%%%Studies have examined MTurk result validity in other domains. 
%%%%%Most relevantly, Heer \etal~\cite{visualperceptionturk} validated MTurk data for graphical perception experiments (spatial encoding and luminance contrast) by replicating previous perceptual studies on MTurk. %The studies yielded similar design guidelines, albeit with greater variability; participant environment, i.e. operation system and graphical display as identified by Javascript, was a factor.
%%%%%% Further, they found the operation system and monitor details, as recorded by Javascript, a predictor of the results. 
%%%%%%\kmC{OS:slc} % KM 01.07: don't understand previous sentence. I tried to rephrase it, but I still am unsure how the environment played into the results. It seems like this counters the point of previous point: the system the subject used was a noise source, which would have gotten in way of validation.
%%%%%Similarly, we compare results of our local user study with an MTurk study to assess viability of running VT studies on MTurk, and collect and examine phone properties in our MTurk deployment. 
%%%%%%Need for Haptic Turk... that's not our title so can we use this? 
%%%%%
%%%%%{\it Need for HapTurk:} Our present goal is to give the haptic design community access to crowdsourced evaluation so we can establish modality-specific methodological tradeoffs.
%%%%%%
%%%%%There is ample need for huge-sample haptic evaluation. User experience of transmitted sensations must be robust to receiving device diversity.
%%%%%Techniques to broadcast haptic effects to video \cite{Modhrain2001,Kim2009}, e.g., with YouTube \cite{AbdurRahman2010} or MPEG7 \cite{Eid2006,Ferre2008} now require known high-fidelity devices  because of remote device uncertainty;  
%%%%%the same applies to social protocols developed for remote use of high-quality vibrations, e.g. in collaborative turn taking \cite{Chan2008}. 
%%%%%Elsewhere, studies of VT use in consumer devices need larger samples: e.g., 
%%%%%perceivability~\cite{Kaaresoja2005}, encoding of caller parameters \cite{Brown2006b}, including caller
%%%%%emotion and physical presence collected from pressure on another handset~\cite{Hoggan2012}, and usability of expressive, customizable VT icons in social messaging~\cite{Israr2015}.
%%%%%%
%%%
%%%
%%%\subsection{Mechanical Turk (MTurk)}
%%%
%%%\purple{Crowdsourced studies have drawbacks. The  remote, asynchronous study environment is not controlled; compared to a quiet lab, participants may be subjected to unknown interruptions, and may spend less time on task with more response variability~\cite{mutrkgeneral}.
%%%MTurk is not suitable for getting rich, qualitative feedback or following up on performance or strategy~\cite{behavioralturk}. Best practices -- e.g., simplifying tasks to be confined to a singular activity, or using instructions complemented with example responses -- are used to reduce task ambiguity and improve response quality~\cite{Amazon.comInc.2015}.
%%%Some participants try to exploit the service for personal profit, exhibiting low task engagement~\cite{Downs2010}, and must be pre- or post-screened.} 
%%%
%%%Studies have examined MTurk result validity in other domains. 
%%%Most relevantly, Heer \etal~\cite{visualperceptionturk} validated MTurk data for graphical perception experiments (spatial encoding and luminance contrast) by replicating previous perceptual studies on MTurk. %The studies yielded similar design guidelines, albeit with greater variability; participant environment, i.e. operation system and graphical display as identified by Javascript, was a factor.
%%%% Further, they found the operation system and monitor details, as recorded by Javascript, a predictor of the results. 
%%%%\kmC{OS:slc} % KM 01.07: don't understand previous sentence. I tried to rephrase it, but I still am unsure how the environment played into the results. It seems like this counters the point of previous point: the system the subject used was a noise source, which would have gotten in way of validation.
%%%Similarly, we compare results of our local user study with an MTurk study to assess viability of running VT studies on MTurk, and collect and examine phone properties in our MTurk deployment. 
%%%%Need for Haptic Turk... that's not our title so can we use this? 
%%%
%%%
%%%
%%%%Hapturk
%%%Recently, Seifi \etal\ compiled research on tactile language into five taxonomies for describing vibrations~\cite{Seifi2015}.  \textbf{1) Physical properties} that can be measured: e.g., duration, energy, tempo or speed, rhythm structure; 
%%%\textbf{2) sensory properties}: roughness, and sensory words from  Guest \etal's touch dictionary \cite{Guest2011};
%%%\textbf{3) emotional interpretations}: pleasantness, arousal (urgency), dictionary emotion words \cite{Guest2011};
%%%\textbf{4) metaphors} provide familiar examples resembling the vibration's feel: heartbeat, insects;
%%%\textbf{5) usage examples} describe % types of 
%%%events which a vibration fits: an incoming message or alarm.
%%%
%%%


%%%
%
% END
%
\endinput

%Any text after an \endinput is ignored.
%You could put scraps here or things in progress.
